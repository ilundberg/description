[
  {
    "objectID": "challenge.html",
    "href": "challenge.html",
    "title": "Challenge Exercise",
    "section": "",
    "text": "This exercise uses models to describe where we have no data at all.\nCaution is always needed when carrying out model-based extrapolation. But when forecasting, a model is also often the only way to make progress.\nYou can generate data as on the Simulate Data page. You can set the sample size however large you want. You can use any model you want.\nYou might discuss methodological choices:\nYou might also discuss conceptual issues:"
  },
  {
    "objectID": "challenge.html#an-example-to-get-you-started",
    "href": "challenge.html#an-example-to-get-you-started",
    "title": "Challenge Exercise",
    "section": "An example to get you started",
    "text": "An example to get you started\nAs a simple example, I might simulate a sample of size 100,\n\nsimulated &lt;- simulate(n = 100)\n\nRows: 420 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (5): year, age, meanlog, sdlog, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nestimate a linear model on those data,\n\nfit &lt;- lm(log(income) ~ sex * year, data = simulated)\n\nand report predictions in 2022.\n\nto_predict &lt;- tibble(\n  sex = c(\"female\",\"male\"),\n  year = c(2022,2022)\n)\nto_predict |&gt;\n  mutate(\n    # Make prediction\n    estimate = predict(fit, newdata = to_predict),\n    # Exponentiate to dollars\n    estimate = exp(estimate)\n  )\n\n# A tibble: 2 × 3\n  sex     year estimate\n  &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 female  2022   62929.\n2 male    2022   52708."
  },
  {
    "objectID": "challenge.html#what-to-try-next",
    "href": "challenge.html#what-to-try-next",
    "title": "Challenge Exercise",
    "section": "What to try next",
    "text": "What to try next\nYou might consider different functional forms, the overall mean, or machine learning estimators."
  },
  {
    "objectID": "simulate_a_sample.html",
    "href": "simulate_a_sample.html",
    "title": "Simulate Data",
    "section": "",
    "text": "This exercise works with simulated samples. Taking the nonparametric estimates from 5 million cases as the truth, you will generate a simulated sample of a much smaller size using the code below.\nPrepare the environment by loading the tidyverse package.\n\nlibrary(tidyverse)\n\nThe function below simulates a sample of 100 cases.\n\nsimulate &lt;- function(n = 100) {\n  read_csv(\"https://ilundberg.github.io/description/assets/truth.csv\") |&gt;\n    slice_sample(n = n, weight_by = weight, replace = T) |&gt;\n    mutate(income = exp(rnorm(n(), meanlog, sdlog))) |&gt;\n    select(year, age, sex, income)\n}\n\nWe can see how it works below.\n\nsimulated &lt;- simulate(n = 100)\n\nRows: 420 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (5): year, age, meanlog, sdlog, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n# A tibble: 100 × 4\n   year   age sex     income\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1  2010    30 male    16882.\n2  2013    36 male    22048.\n3  2017    45 female 154609.\n# ℹ 97 more rows"
  },
  {
    "objectID": "evaluate.html",
    "href": "evaluate.html",
    "title": "Evaluate Models",
    "section": "",
    "text": "This page presents a \\(\\hat{Y}\\) view of what it means for one model to outperform another model. We first discuss in a simulated setting where we generate many samples from the population and directly observe performance of estimators across those simulated samples. Then, we discuss how one can evaluate performance in the more realistic setting in which only one sample from the population is available,"
  },
  {
    "objectID": "evaluate.html#estimator-functions",
    "href": "evaluate.html#estimator-functions",
    "title": "Evaluate Models",
    "section": "Estimator functions",
    "text": "Estimator functions\nThe functions below is an estimator: it take data in and returns estimates. This function can be applied with the flat, linear, and quadratic models defiend on the previous page.\n\nestimator &lt;- function(\n    data, # from simulate()\n    model_name # one of \"flat\", \"linear\", \"quadratic\"\n) {\n  # Estimate a regression model\n  if (model_name == \"flat\") {\n    fit &lt;- lm(log(income) ~ sex, data = data)\n  } else if (model_name == \"linear\") {\n    fit &lt;- lm(log(income) ~ sex * age, data = data)\n  } else if (model_name == \"quadratic\") {\n    fit &lt;- lm(log(income) ~ sex * poly(age,2), data = data)\n  }\n  # Define x-values at which to make predictions\n  to_predict &lt;- tibble(\n    sex = c(\"female\",\"male\"),\n    age = c(30,30)\n  )\n  # Make predictions\n  predicted &lt;- to_predict |&gt;\n    mutate(estimate = predict(fit, newdata = to_predict)) |&gt;\n    # Transform from log scale to dollars scale\n    mutate(estimate = exp(estimate)) |&gt;\n    # Append information for summarizing later\n    mutate(\n      model_name = model_name,\n      sample_size = nrow(data)\n    )\n  # Return the predicted estimates\n  return(predicted)\n}\n\nAs an illustration, here is the linear estimator applied to a simulated sample\n\nsimulated &lt;- simulate(n = 100)\n\nRows: 420 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (5): year, age, meanlog, sdlog, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nestimator(data = simulated, model_name = \"linear\")\n\n# A tibble: 2 × 5\n  sex      age estimate model_name sample_size\n  &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;            &lt;int&gt;\n1 female    30   35102. linear             100\n2 male      30   46860. linear             100"
  },
  {
    "objectID": "evaluate.html#apply-estimators-in-repeated-samples",
    "href": "evaluate.html#apply-estimators-in-repeated-samples",
    "title": "Evaluate Models",
    "section": "Apply estimators in repeated samples",
    "text": "Apply estimators in repeated samples\nHow do our estimators perform in repeated samples? In actual problems, one only has one sample. But we created this exercise so that we can use simulate() to simulate many samples from a known data generating process. The code below applies the estimator to many samples of size 100.\nWe first prepare for parallel computing.\n\nlibrary(foreach)\nlibrary(doParallel)\nlibrary(doRNG)\ncl &lt;- makeCluster(detectCores())\nregisterDoParallel(cl)\n\nThen we apply the estimator many times at each of a series of sample sizes.\n\nsimulations &lt;- foreach(\n  repetition = 1:1000, \n  .combine = \"rbind\", \n  .packages = \"tidyverse\"\n) %dorng% {\n  foreach(n_value = c(50,100,200,500,1000), .combine = \"rbind\") %do% {\n    # Simulate data\n    simulated &lt;- simulate(n = n_value)\n    # Apply the three estimators\n    flat &lt;- estimator(data = simulated, model_name = \"flat\")\n    linear &lt;- estimator(data = simulated, model_name = \"linear\")\n    quadratic &lt;- estimator(data = simulated, model_name = \"quadratic\")\n    # Return estimates\n    all_estimates &lt;- rbind(flat, linear, quadratic)\n    return(all_estimates)\n  }\n}"
  },
  {
    "objectID": "evaluate.html#visualize-estimator-performance",
    "href": "evaluate.html#visualize-estimator-performance",
    "title": "Evaluate Models",
    "section": "Visualize estimator performance",
    "text": "Visualize estimator performance\nFor simplicity, we first focus on one estimand and sample size: modeling the geometric mean of 30-year-old female incomes with a sample size of \\(n = 100\\). Despite having good performance in the population, the quadratic model has poor performance at this sample size because it has high variance!\n\n\n\n\n\n\n\n\n\nTo aggregate simulations to a summary score, we use mean squared error (MSE) on the scale of log incomes.\n\\[\\begin{aligned}\n\\theta(\\vec{x}) &= \\text{True geometric mean in subgroup }\\vec{x} \\\\\n\\hat\\theta_r(\\vec{x}) &= \\text{Estimated geometric mean in subgroup }\\vec{x}\\text{ in simulated sample }r \\\\\n\\widehat{\\text{MSE}}\\bigg(\\hat\\theta(\\vec{x})\\bigg) &= \\frac{1}{R}\\sum_{r=1}^R \\left(\\text{log}(\\hat\\theta) - \\text{log}(\\theta)\\right)^2\n\\end{aligned}\\]\nThe figure below reports MSE for each estimator at each sample size."
  },
  {
    "objectID": "evaluate.html#conclusions",
    "href": "evaluate.html#conclusions",
    "title": "Evaluate Models",
    "section": "Conclusions",
    "text": "Conclusions\nThe results indicate that\n\nin a small sample (\\(n = 50\\)), the flat model is best\nthe linear model becomes best\n\nat \\(n = 100\\) for the male subgroup\nat \\(n = 500\\) for the female subgroup\n\nthe quadratic model becomes best\n\nat \\(n = 1,000\\) in the male subgroup\nat some higher sample size in the female subgroup\n\n\nThere are two main conclusions from this illustration. Which estimator is best is a question that\n\ndepends on the estimand (male or female subgroup), and\ndepends on the sample size\n\nFurther, although the quadratic fit is best in the population (previous page), a very large sample size is needed before it is best in a sample. This is a reminder that more complex models do not necessarily outperform simpler models, especially in small samples."
  },
  {
    "objectID": "evaluate.html#split-into-learning-and-evaluation-sets",
    "href": "evaluate.html#split-into-learning-and-evaluation-sets",
    "title": "Evaluate Models",
    "section": "Split into learning and evaluation sets",
    "text": "Split into learning and evaluation sets\nCreate a learning set with half of the cases.\n\nlearning &lt;- simulated |&gt;\n  slice_sample(prop = .5)\n\nCreate an evaluation set with the other half.\n\nevaluation &lt;- simulated |&gt;\n  anti_join(learning, by = join_by(id))"
  },
  {
    "objectID": "evaluate.html#estimate-models-in-the-learning-set",
    "href": "evaluate.html#estimate-models-in-the-learning-set",
    "title": "Evaluate Models",
    "section": "Estimate models in the learning set",
    "text": "Estimate models in the learning set\nNext, estimate the models in the learning set.\n\nflat &lt;- lm(log(income) ~ sex, data = learning)\nlinear &lt;- lm(log(income) ~ sex * age, data = learning)\nquadratic &lt;- lm(log(income) ~ sex * poly(age,2), data = learning)"
  },
  {
    "objectID": "evaluate.html#evaluate-in-the-evaluation-set",
    "href": "evaluate.html#evaluate-in-the-evaluation-set",
    "title": "Evaluate Models",
    "section": "Evaluate in the evaluation set",
    "text": "Evaluate in the evaluation set\nUse them to predict in the evaluation set.\n\npredicted &lt;- evaluation |&gt;\n  mutate(\n    flat = predict(flat, newdata = evaluation),\n    linear = predict(linear, newdata = evaluation),\n    quadratic = predict(quadratic, newdata = evaluation)\n  )\n\nAggregate prediction errors in the evaluation set to produce mean squared error estimates for each model.\n\nperformance &lt;- predicted |&gt;\n  # Select the actual and predicted values\n  mutate(actual = log(income)) |&gt;\n  select(actual, flat, linear, quadratic) |&gt;\n  # Make a long dataset for ease of analysis\n  pivot_longer(cols = -actual, names_to = \"model_name\", values_to = \"prediction\") |&gt;\n  # Create a column with errors\n  mutate(squared_error = (actual - prediction) ^ 2) |&gt;\n  # Summarize mean squared error\n  group_by(model_name) |&gt;\n  summarize(mse = mean(squared_error)) |&gt;\n  print()\n\n# A tibble: 3 × 2\n  model_name   mse\n  &lt;chr&gt;      &lt;dbl&gt;\n1 flat       0.619\n2 linear     0.618\n3 quadratic  0.655\n\n\nOur split-sample procedure estimates that the linear model has the best performance!"
  },
  {
    "objectID": "evaluate.html#difficulties-in-split-sample-model-evaluation",
    "href": "evaluate.html#difficulties-in-split-sample-model-evaluation",
    "title": "Evaluate Models",
    "section": "Difficulties in split-sample model evaluation",
    "text": "Difficulties in split-sample model evaluation\n\nthe estimated performance may itself be statistically uncertain\nif the best model in one subgroup is different from the best in another subgroup, then a sample-average MSE may not be optimal for selecting for our task"
  },
  {
    "objectID": "define_models.html",
    "href": "define_models.html",
    "title": "Why model?",
    "section": "",
    "text": "We model because"
  },
  {
    "objectID": "define_models.html#generate-an-illustration-sample",
    "href": "define_models.html#generate-an-illustration-sample",
    "title": "Why model?",
    "section": "Generate an illustration sample",
    "text": "Generate an illustration sample\nThe code below will generate a sample of 100 respondents simulated to correspond to the target population ages 30–50 in 2010–2019.\n\nsimulate &lt;- function(n = 100) {\n  read_csv(\"assets/truth.csv\") |&gt;\n    slice_sample(n = n, weight_by = weight, replace = T) |&gt;\n    mutate(income = exp(rnorm(n(), meanlog, sdlog))) |&gt;\n    select(year, age, sex, income)\n}\n\n\nsimulated &lt;- simulate(n = 100)\n\n\n\n# A tibble: 100 × 4\n   year   age sex    income\n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1  2014    40 male   34984.\n2  2011    49 male   27677.\n3  2019    49 female 10747.\n# ℹ 97 more rows"
  },
  {
    "objectID": "define_models.html#target-estimand",
    "href": "define_models.html#target-estimand",
    "title": "Why model?",
    "section": "Target estimand",
    "text": "Target estimand\nWe will estimate three target quantities:\n\n\ngeometric mean pay among female respondents age 30\n\n\ngeometric mean pay among male respondents age 30\n\n\nratio (1) / (2)\n\n\nIn our sample, there are only 2 female and 4 male 30-year-olds! We will need a model."
  },
  {
    "objectID": "define_models.html#models-for-illustration",
    "href": "define_models.html#models-for-illustration",
    "title": "Why model?",
    "section": "Models for illustration",
    "text": "Models for illustration\nWe consider a series of three models.\n\nFlat model: Geometric mean among everyone\nLinear model: Prediction from linear fit on age \\(\\times\\) sex\nQuadratic model: Prediction from quadratic fit on age \\(\\times\\) sex\n\nRecall that each model is a tool to share information from other cases in order to predict an estimate for the target subgroups: 30-year-old male and female respondents.\n\n\nRows: 420 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (5): year, age, meanlog, sdlog, weight\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n`summarise()` has grouped output by 'sex'. You can override using the `.groups` argument.\n\n\n\n\n\n\n\n\n\nWe will use these models for a task: estimate the geometric mean pay among 30-year-old male and female respondents. We will carry out the task in a simulated sample of 100 respondents."
  },
  {
    "objectID": "define_models.html#which-model-would-you-choose",
    "href": "define_models.html#which-model-would-you-choose",
    "title": "Why model?",
    "section": "Which model would you choose?",
    "text": "Which model would you choose?\nThink about an answer before going on to the next page."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Description: Using models to describe",
    "section": "",
    "text": "This page introduces an ongoing collaborative project by Ian Lundberg and Kristin Liao at UCLA.\nDescriptive research summarizes the world as it exists. Description may not require a model—the mean of an outcome in a simple random sample can be a powerful form of description. This tutorial first considers model-free description and then pivots to a view of model-based description.\nWe take a \\(\\hat{Y}\\) view as opposed to a \\(\\hat\\beta\\) view of model-based description. This view is in some sense both radical and conventional.\nBecause our view pushes beyond \\(\\hat\\beta\\), an additional upside is that it opens the door to machine learning estimators for description that may not be parameterized by coefficients."
  },
  {
    "objectID": "index.html#concrete-setting",
    "href": "index.html#concrete-setting",
    "title": "Description: Using models to describe",
    "section": "Concrete setting",
    "text": "Concrete setting\nUsing data from the 2010–2019 American Community Survey (ACS), we describe sex gaps in pay. We focus on the subgroup of adults ages 30–50 who worked for pay full-time (35+ hours per week) and for the full year (50+ weeks). Our outcome \\(Y\\) is annual wage and salary income. We summarize by the geometric mean (the exponentiated mean of log income), and we report the female / male ratio of geometric mean pay."
  },
  {
    "objectID": "index.html#model-free-description",
    "href": "index.html#model-free-description",
    "title": "Description: Using models to describe",
    "section": "Model-free description",
    "text": "Model-free description\nLet \\(Y\\) be the income of a randomly sampled person from our population. With a large sample, one could summarize the geometric mean of \\(Y\\) by a sample mean estimator.\n\\[\\widehat{\\text{GM}}(Y) = \\text{exp}\\left(\\frac{1}{n}\\sum_{i=1}^n \\text{log}(y_i)\\right)\\]\nWe next consider a subgroup summary: the geometric mean among female respondents age 30. Letting \\(\\vec{X}\\) denote the values of these two features for a randomly sampled person and \\(\\vec{x}\\) denoting the particular values of interest, we could estimate by the sample mean of the target subgroup.\n\\[\\widehat{GM}(Y\\mid\\vec{X} = \\vec{x}) = \\text{exp}\\left(\\frac{1}{n_\\vec{x}}\\sum_{i:\\vec{X}_i=\\vec{x}} \\text{log}(y_i)\\right)\\] where the sum is over people whose feature vector \\(\\vec{X}\\) equals the target value \\(\\vec{x}\\) (e.g., female respondents age 30) and the number of people in the subgroup is \\(n_{\\vec{x}}\\).\nSmall sample sizes become a problem for model-free subgroup description. Even in a large sample, there may be few female respondents who are 30 years old."
  },
  {
    "objectID": "index.html#model-based-description",
    "href": "index.html#model-based-description",
    "title": "Description: Using models to describe",
    "section": "Model-based description",
    "text": "Model-based description\nIn a sample with very few 30-year-old female respondents, one might consider whether other respondents might be informative. Perhaps 31-year-old female respondents or 30-year-old male respondents provide data that could be informative about the pay of 30-year-old female respondents.\nFor us, a model is a tool to pool information from units outside the target subgroup in order to produce a better estimate within the target subgroup.\nFormally, let \\(\\hat{f}()\\) be a learned model: a function that maps a feature vector \\(\\vec{x}\\) to a predicted outcome \\(\\hat{f}(\\vec{x})\\). The predicted value is an estimate of some summary of the conditional distribution of \\(Y\\) among those with the feature set \\(\\vec{X} = \\vec{x}\\).\nFor example, we might fit a linear regression model for log income.\n\\[\\begin{aligned}\n&\\widehat{E}(\\text{log}(Y)\\mid \\vec{X} = \\vec{x}) \\\\&= \\vec{x}'\\hat{\\vec\\beta} \\\\&= \\hat\\beta_0 + \\hat\\beta_1(\\text{Female}) + \\hat\\beta_2(\\text{Age}) + \\hat\\beta_3(\\text{Female}\\times\\text{Age})\n\\end{aligned}\\]\nThe prediction function for geometric mean pay would then be the exponentiated value of predicted log pay.\n\\[\\widehat{\\text{GM}}(Y\\mid \\vec{X} = \\vec{x}) = \\hat{f}(\\vec{x}) = \\text{exp}(\\vec{x}'\\hat{\\vec\\beta})\\]"
  },
  {
    "objectID": "index.html#the-choice",
    "href": "index.html#the-choice",
    "title": "Description: Using models to describe",
    "section": "The choice",
    "text": "The choice\nWe would prefer\n\nmodel-free description when there are enough cases\nmodel-based description when data are scarce\n\nas long as our model pools information effectively. Data can help us decide!\nWhat comes next:\n\nfirst generate some simulated data\nthen apply a model-free estimator\nthen apply an OLS model-based estimator\nthen apply a more flexible spline estimator"
  }
]